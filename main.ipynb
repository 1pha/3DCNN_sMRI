{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T06:20:01.452901Z",
     "start_time": "2020-12-09T06:19:57.214379Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n",
    "# for reading and displaying images\n",
    "# from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import *\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "for kFold, it will be run again on the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T06:20:27.574375Z",
     "start_time": "2020-12-09T06:20:27.218377Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.dataloader import *\n",
    "\n",
    "train_dset = MyDataset(task_type='age')\n",
    "test_dset = MyDataset(task_type='age', test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=8)\n",
    "test_loader = DataLoader(test_dset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Dinsdale is selected.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 GiB (GPU 0; 6.00 GiB total capacity; 623.65 MiB already allocated; 3.64 GiB free; 634.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4c77379a638c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\내 드라이브\\brain_data\\workspace\\3d_brain\\src\\architectures\\dinsdale.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\내 드라이브\\brain_data\\workspace\\3d_brain\\src\\architectures\\dinsdale.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mada_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36madaptive_avg_pool3d\u001b[1;34m(input, output_size)\u001b[0m\n\u001b[0;32m    944\u001b[0m                 adaptive_avg_pool3d, (input,), input, output_size)\n\u001b[0;32m    945\u001b[0m     \u001b[0m_output_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_with_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_output_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 GiB (GPU 0; 6.00 GiB total capacity; 623.65 MiB already allocated; 3.64 GiB free; 634.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = 'dinsdale'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Model {model.capitalize()} is selected.')\n",
    "\n",
    "\n",
    "if model == 'resnet':\n",
    "    from src.architectures.resnet import *\n",
    "\n",
    "    opt = Option()\n",
    "    model = generate_model(model_depth=opt.model_depth,\n",
    "                                n_classes=opt.n_classes,\n",
    "                                n_input_channels=opt.n_input_channels,\n",
    "                                shortcut_type=opt.shortcut_type,\n",
    "                                conv1_t_size=opt.conv1_t_size,\n",
    "                                conv1_t_stride=opt.conv1_t_stride,\n",
    "                                no_max_pool=opt.no_max_pool,\n",
    "                                widen_factor=opt.resnet_widen_factor)\n",
    "    \n",
    "    \n",
    "elif model == 'levakov':\n",
    "    \n",
    "    from src.architectures.levakov_96 import *\n",
    "    model = Levakov(task_type='age')\n",
    "    \n",
    "    \n",
    "elif model == 'inception':\n",
    "    \n",
    "    from src.architectures.inception import *\n",
    "    model = Inception3()\n",
    "    \n",
    "elif model == 'dinsdale':\n",
    "    \n",
    "    from src.architectures.dinsdale import *\n",
    "    model = Dinsdale(1, 1, [16, 32, 32, 32, 64])\n",
    "\n",
    "else: pass\n",
    "\n",
    "model.to(device)\n",
    "print(summary(model, input_size=(1, 96, 96, 96)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'age' # no longer used.\n",
    "resize = True\n",
    "scheduler = False\n",
    "epochs = range(100)\n",
    "folds = range(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import RMSELoss\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "lamb = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_fn = RMSELoss()\n",
    "mae_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kFold Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 6.00 GiB total capacity; 4.15 GiB already allocated; 92.63 MiB free; 4.17 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a36ab4dedcd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                                                               \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                                                               \u001b[0mtrn_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_maes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_rmses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                                                               optimizer, scheduler, lamb)\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         model, (val_losses, val_maes, val_rmses), val_preds =  eval(model, valid_loader, resize, device,\n",
      "\u001b[1;32m<ipython-input-8-93b2bb34759b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, resize, device, loss_fn, mae_fn, rmse_fn, losses, maes, rmses, optimizer, scheduler, lamb)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtrues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\내 드라이브\\brain_data\\workspace\\3d_brain\\src\\architectures\\dinsdale.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\내 드라이브\\brain_data\\workspace\\3d_brain\\src\\architectures\\dinsdale.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv3d_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;31m# x = self.Conv3d_2(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\1pha\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    565\u001b[0m                             self.dilation, self.groups)\n\u001b[0;32m    566\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 567\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 6.00 GiB total capacity; 4.15 GiB already allocated; 92.63 MiB free; 4.17 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "best_loss = 10\n",
    "\n",
    "trn_fold_losses, tst_fold_losses = [], []\n",
    "trn_fold_corrs, tst_fold_corrs = [], []\n",
    "\n",
    "trn_fold = {\n",
    "    'MSE': list(),\n",
    "    'MAE': list(),\n",
    "    'RMSE': list(),\n",
    "    'Correlation': list()\n",
    "}\n",
    "\n",
    "val_fold = {\n",
    "    'MSE': list(),\n",
    "    'MAE': list(),\n",
    "    'RMSE': list(),\n",
    "    'Correlation': list()\n",
    "}\n",
    "\n",
    "tst_losses, tst_maes, tst_rmses = [], [], []\n",
    "for fold in folds:\n",
    "    \n",
    "    train_dset = MyDataset(task_type='age', fold=fold)\n",
    "    valid_dset = MyDataset(task_type='age', test=True, fold=fold)\n",
    "\n",
    "    train_loader = DataLoader(train_dset, batch_size=8)\n",
    "    valid_loader = DataLoader(valid_dset, batch_size=8)\n",
    "    \n",
    "    trn_losses, val_losses = [], []\n",
    "    trn_maes, val_maes = [], []\n",
    "    trn_rmses, val_rmses = [], []\n",
    "    \n",
    "    for e in epochs:\n",
    "\n",
    "        model, (trn_losses, trn_maes, trn_rmses), trn_preds = train(model, train_loader, resize, device,\n",
    "                                                              loss_fn, mae_fn, rmse_fn,\n",
    "                                                              trn_losses, trn_maes, trn_rmses,\n",
    "                                                              optimizer, scheduler, lamb)\n",
    "        \n",
    "        model, (val_losses, val_maes, val_rmses), val_preds =  eval(model, valid_loader, resize, device,\n",
    "                                                              loss_fn, mae_fn, rmse_fn,\n",
    "                                                              val_losses, val_maes, val_rmses)\n",
    "\n",
    "\n",
    "        # SUM UP RESLUTS\n",
    "        trn_df = make_df(trn_preds, 'train')\n",
    "        val_df = make_df(val_preds, 'valid')\n",
    "        reg_df = pd.concat([trn_df, val_df], ignore_index=True)\n",
    "\n",
    "        trn_corr = reg_df[reg_df['Label'] == 'train'].corr().Prediction['True']\n",
    "        val_corr = reg_df[reg_df['Label'] == 'valid'].corr().Prediction['True']\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(f'FOLD {fold} - EPOCHS {e}')\n",
    "            print(f'MSE  :: [TRAIN] {trn_losses[-1]:.3f} | [VALID] {val_losses[-1]:.3f}')\n",
    "            print(f'MAE  :: [TRAIN] {trn_maes[-1]:.3f}   | [VALID] {val_maes[-1]:.3f}')\n",
    "            print(f'RMSE :: [TRAIN] {trn_rmses[-1]:.3f}  | [VALID] {val_rmses[-1]:.3f}')\n",
    "            print(f'CORR :: [TRAIN] {trn_corr:.3f} | [VALID] {val_corr:.3f}')\n",
    "\n",
    "        if e % 10 == 9:\n",
    "            plt.title(f\"L1 Losses among epochs, {e}th\")\n",
    "            plt.plot(trn_losses, label='Train')\n",
    "            plt.plot(val_losses, label='Valid')\n",
    "            plt.grid(); plt.legend()\n",
    "            \n",
    "            sns.lmplot(data=reg_df, x='True', y='Prediction', hue='Label')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "    \n",
    "    trn_fold['MSE'].append(trn_losses)\n",
    "    trn_fold['MAE'].append(trn_maes)\n",
    "    trn_fold['RMSE'].append(trn_rmses)\n",
    "    trn_fold['Correlation'].append(trn_corr)\n",
    "    \n",
    "    val_fold['MSE'].append(val_losses)\n",
    "    val_fold['MAE'].append(val_maes)\n",
    "    val_fold['RMSE'].append(val_rmses)\n",
    "    val_fold['Correlation'].append(val_corr)\n",
    "    \n",
    "    # TEST\n",
    "    test_dset = MyDataset(task_type='age', test=True)\n",
    "    test_loader = DataLoader(test_dset, batch_size=8)\n",
    "    \n",
    "    model, (tst_losses, tst_maes, tst_rmses), tst_preds = eval(model, test_loader, resize, device,\n",
    "                                                              loss_fn, mae_fn, rmse_fn,\n",
    "                                                              tst_losses, tst_maes, tst_rmses)\n",
    "\n",
    "    tst_df = make_df(tst_preds, 'test')\n",
    "    reg_df = pd.concat([reg_df, tst_df], ignore_index=True)\n",
    "\n",
    "    tst_corr = reg_df[reg_df['Label'] == 'test'].corr().Prediction['True']\n",
    "    \n",
    "    print(f'FOLD {fold}', end='')\n",
    "    print(f'MSE  :: [TEST] {tst_losses[-1]:.3f}')\n",
    "    print(f'MAE  :: [TEST] {tst_maes[-1]:.3f}')\n",
    "    print(f'RMSE :: [TEST] {tst_rmses[-1]:.3f}')\n",
    "    print(f'CORR :: [TEST] {tst_corr:.3f}')\n",
    "\n",
    "    sns.lmplot(data=reg_df, x='True', y='Prediction', hue='Label')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(data, label):\n",
    "    \n",
    "    trues, preds = data\n",
    "    return pd.DataFrame({\n",
    "        'True': list(map(float, trues)),\n",
    "        'Prediction': list(map(float, preds)),\n",
    "        'Label': [label] * len(trues)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, resize, device,\n",
    "          loss_fn, mae_fn, rmse_fn,\n",
    "          losses, maes, rmses,\n",
    "          optimizer, scheduler, lamb):\n",
    "    \n",
    "    bth_loss, bth_mae, bth_rmse = 0, 0, 0\n",
    "    trues, preds = [], []\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "\n",
    "        if resize:\n",
    "            x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "        else:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model.forward(x).to(device)\n",
    "\n",
    "        trues.append(y.to('cpu'))\n",
    "        preds.append(y_pred.to('cpu'))\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred.squeeze(1), y)\n",
    "        \n",
    "        if lamb:\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += lamb * l2_reg\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mae_fn(y_pred.squeeze(1), y)\n",
    "        rmse = rmse_fn(y_pred.squeeze(1), y)\n",
    "\n",
    "        del x, y, y_pred\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler: scheduler.step()\n",
    "\n",
    "        bth_loss += loss.item()\n",
    "        bth_mae  += mae.item()\n",
    "        bth_rmse += rmse.item()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ### loss\n",
    "    M = len(dataloader)\n",
    "    losses.append(bth_loss / M)\n",
    "    maes.append(bth_mae / M)\n",
    "    rmses.append(bth_rmse / M)\n",
    "\n",
    "    ### collect trues/predictions\n",
    "    trues = list(chain(*trues))\n",
    "    preds = list(chain(*preds))\n",
    "    \n",
    "    return model, (losses, maes, rmses), (trues, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader, resize, device,\n",
    "          loss_fn, mae_fn, rmse_fn,\n",
    "        losses, maes, rmses):\n",
    "    \n",
    "    bth_loss, bth_mae, bth_rmse = 0, 0, 0\n",
    "    trues, preds = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # to not give loads on GPU... :(\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            if resize:\n",
    "                x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model.forward(x).to(device)\n",
    "\n",
    "            trues.append(y.to('cpu'))\n",
    "            preds.append(y_pred.to('cpu'))\n",
    "\n",
    "            # Loss\n",
    "            loss = loss_fn(y_pred.squeeze(1), y)\n",
    "\n",
    "            # Metrics\n",
    "            mae = mae_fn(y_pred.squeeze(1), y)\n",
    "            rmse = rmse_fn(y_pred.squeeze(1), y)\n",
    "\n",
    "            del x, y, y_pred\n",
    "\n",
    "            bth_loss += loss.item()\n",
    "            bth_mae  += mae.item()\n",
    "            bth_rmse += rmse.item()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ### loss\n",
    "    M = len(dataloader)\n",
    "    losses.append(bth_loss / M)\n",
    "    maes.append(bth_mae / M)\n",
    "    rmses.append(bth_rmse / M)\n",
    "\n",
    "    ### collect trues/predictions\n",
    "    trues = list(chain(*trues))\n",
    "    preds = list(chain(*preds))\n",
    "    \n",
    "    return model, (losses, maes, rmses), (trues, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T06:31:47.469052Z",
     "start_time": "2020-12-09T06:31:47.237052Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2ac278e2d1dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtrain_dset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "best_loss = 10\n",
    "\n",
    "trn_fold_losses, tst_fold_losses = [], []\n",
    "trn_fold_corrs, tst_fold_corrs = [], []\n",
    "\n",
    "trn_fold = {\n",
    "    'MSE': list(),\n",
    "    'MAE': list(),\n",
    "    'RMSE': list(),\n",
    "    'Correlation': list()\n",
    "}\n",
    "\n",
    "tst_fold = {\n",
    "    'MSE': list(),\n",
    "    'MAE': list(),\n",
    "    'RMSE': list(),\n",
    "    'Correlation': list()\n",
    "}\n",
    "\n",
    "for fold in folds:\n",
    "    \n",
    "    train_dset = MyDataset(task_type='age', fold=fold)\n",
    "    test_dset = MyDataset(task_type='age', test=True, fold=fold)\n",
    "\n",
    "    train_loader = DataLoader(train_dset, batch_size=8)\n",
    "    test_loader = DataLoader(test_dset, batch_size=8)\n",
    "    \n",
    "    trn_losses, tst_losses = [], []\n",
    "    trn_maes, tst_maes = [], []\n",
    "    trn_rmses, tst_rmses = [], []\n",
    "    for e in epochs:\n",
    "\n",
    "        # TRAIN\n",
    "        trn_bth_loss, trn_bth_mae, trn_bth_rmse = 0, 0, 0\n",
    "        trn_trues, trn_preds = [], []\n",
    "        model.train()\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if resize:\n",
    "                x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model.forward(x).to(device)\n",
    "\n",
    "            trn_trues.append(y.to('cpu'))\n",
    "            trn_preds.append(y_pred.to('cpu'))\n",
    "\n",
    "            # Loss\n",
    "            loss = loss_fn(y_pred.squeeze(1), y)\n",
    "            \n",
    "            # Metrics\n",
    "            mae = mae_fn(y_pred.squeeze(1), y)\n",
    "            rmse = rmse_fn(y_pred.squeeze(1), y)\n",
    "            \n",
    "            del x, y, y_pred\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler: scheduler.step()\n",
    "\n",
    "            trn_bth_loss += loss.item()\n",
    "            trn_bth_mae  += loss.item()\n",
    "            trn_bth_rmse += loss.item()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        ### loss\n",
    "        trn_losses.append(trn_bth_loss / len(train_loader))\n",
    "        trn_maes.append(trn_bth_mae / len(train_loader))\n",
    "        trn_rmses.append(trn_bth_rmse / len(train_loader))\n",
    "\n",
    "        ### collect trues/predictions\n",
    "        trn_trues = list(chain(*trn_trues))\n",
    "        trn_preds = list(chain(*trn_preds))\n",
    "\n",
    "        \n",
    "        # VALID\n",
    "        tst_bth_loss, tst_bth_mae, tst_bth_rmse = 0, 0, 0\n",
    "        model.eval()\n",
    "        tst_trues, tst_preds = [], []\n",
    "        with torch.no_grad(): # to not give loads on GPU... :(\n",
    "            for i, (x, y) in enumerate(test_loader):\n",
    "                if resize:\n",
    "                    x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "                else:\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "\n",
    "                y_pred = model.forward(x).to(device)\n",
    "\n",
    "                tst_trues.append(y.to('cpu'))\n",
    "                tst_preds.append(y_pred.to('cpu'))\n",
    "\n",
    "                # Loss\n",
    "                loss = loss_fn(y_pred.squeeze(1), y)\n",
    "                \n",
    "                # Metrics\n",
    "                mae = mae_fn(y_pred.squeeze(1), y)\n",
    "                rmse = rmse_fn(y_pred.squeeze(1), y)\n",
    "                \n",
    "                del x, y, y_pred\n",
    "\n",
    "                tst_bth_loss += loss.item()\n",
    "                tst_bth_mae  += loss.item()\n",
    "                tst_bth_rmse += loss.item()\n",
    "                \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        ### loss\n",
    "        tst_losses.append(tst_bth_loss / len(test_loader))\n",
    "        tst_maes.append(tst_bth_mae / len(test_loader))\n",
    "        tst_rmses.append(tst_bth_rmse / len(test_loader))\n",
    "\n",
    "        ### collect trues/predictions\n",
    "        tst_trues = list(chain(*tst_trues))\n",
    "        tst_preds = list(chain(*tst_preds))\n",
    "\n",
    "        \n",
    "        # SUM UP RESLUTS\n",
    "        reg_df = pd.DataFrame({\n",
    "            'True': list(map(float, trn_trues + tst_trues)),\n",
    "            'Prediction': list(map(float, trn_preds + tst_preds)),\n",
    "            'Label': ['train'] * len(trn_trues) + ['valid'] * len(tst_trues)\n",
    "        })\n",
    "\n",
    "        trn_corr = reg_df[reg_df['Label'] == 'train'].corr().Prediction['True']\n",
    "        tst_corr = reg_df[reg_df['Label'] == 'valid'].corr().Prediction['True']\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print(f'FOLD {fold} - EPOCHS {e}')\n",
    "            print(f'MSE  :: [TRAIN] {trn_losses[-1]:.3f} | [VALID] {tst_losses[-1]:.3f}')\n",
    "            print(f'MAE  :: [TRAIN] {trn_maes[-1]:.3f}   | [VALID] {tst_maes[-1]:.3f}')\n",
    "            print(f'RMSE :: [TRAIN] {trn_rmses[-1]:.3f}  | [VALID] {tst_rmses[-1]:.3f}')\n",
    "            print(f'CORR :: [TRAIN] {trn_corr:.3f} | [VALID] {tst_corr:.3f}')\n",
    "\n",
    "        if e % 10 == 9:\n",
    "            plt.title(f\"L1 Losses among epochs, {e}th\")\n",
    "            plt.plot(trn_losses, label='Train')\n",
    "            plt.plot(tst_losses, label='Valid')\n",
    "            plt.grid(); plt.legend()\n",
    "            \n",
    "            sns.lmplot(data=reg_df, x='True', y='Prediction', hue='Label')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "    \n",
    "    trn_fold['MSE'].append(trn_losses)\n",
    "    trn_fold['MAE'].append(trn_maes)\n",
    "    trn_fold['RMSE'].append(trn_rmses)\n",
    "    trn_fold['Correlation'].append(trn_corr)\n",
    "    \n",
    "    tst_fold['MSE'].append(tst_losses)\n",
    "    tst_fold['MAE'].append(tst_maes)\n",
    "    tst_fold['RMSE'].append(tst_rmses)\n",
    "    tst_fold['Correlation'].append(tst_corr)\n",
    "    \n",
    "    # TEST\n",
    "    test_dset = MyDataset(task_type='age', test=True)\n",
    "    test_loader = DataLoader(test_dset, batch_size=8)\n",
    "    \n",
    "    tst_bth_loss = 0\n",
    "    model.eval()\n",
    "    tst_trues, tst_preds = [], []\n",
    "    with torch.no_grad(): # to not give loads on GPU... :(\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            if resize:\n",
    "                x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model.forward(x).to(device)\n",
    "\n",
    "            tst_trues.append(y.to('cpu'))\n",
    "            tst_preds.append(y_pred.to('cpu'))\n",
    "\n",
    "            loss = loss_fn(y_pred.squeeze(1), y)\n",
    "            \n",
    "            mae = mae_fn(y_pred.squeeze(1), y)\n",
    "            rmse = rmse_fn(y_pred.squeeze(1), y)\n",
    "            del x, y, y_pred\n",
    "\n",
    "            tst_bth_loss += loss.item()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    ### loss\n",
    "    tst_loss = tst_bth_loss / len(test_loader)\n",
    "\n",
    "    ### collect trues/predictions\n",
    "    tst_trues = list(chain(*tst_trues))\n",
    "    tst_preds = list(chain(*tst_preds))\n",
    "    \n",
    "    tst_df = pd.DataFrame({\n",
    "        'True': list(map(float, tst_trues)),\n",
    "        'Prediction': list(map(float, tst_preds)),\n",
    "        'Label': ['test'] * len(tst_trues)\n",
    "    })\n",
    "    reg_df = pd.concat([reg_df, tst_df], ignore_index=True)\n",
    "\n",
    "    tst_corr = reg_df[reg_df['Label'] == 'test'].corr().Prediction['True']\n",
    "    print(f'FOLD {fold}', end='')\n",
    "    print(f'RMSE :: [TEST] {tst_loss:.3f}')\n",
    "    print(f'CORR :: [TEST] {tst_corr:.3f}')\n",
    "\n",
    "    sns.lmplot(data=reg_df, x='True', y='Prediction', hue='Label')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
