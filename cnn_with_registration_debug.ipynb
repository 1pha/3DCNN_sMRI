{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:31.785706Z",
     "start_time": "2020-11-03T07:12:28.697190Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn.image import resample_img\n",
    "from nilearn.image import new_img_like, load_img, clean_img, crop_img\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from scipy.stats import zscore\n",
    "from glob import glob\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import *\n",
    "import h5py\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:31.801708Z",
     "start_time": "2020-11-03T07:12:31.787707Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, task_type, test_size=0.2, test=False, scaler='minmax',\n",
    "                path='../../brainmask_reg/*.npy'):\n",
    "\n",
    "        self.scaler = scaler\n",
    "\n",
    "        RANDOM_STATE = 42\n",
    "        np.random.seed(RANDOM_STATE)\n",
    "\n",
    "        data_files = glob(path)\n",
    "        data_files.sort()\n",
    "\n",
    "        test_num = int(test_size * len(data_files))\n",
    "        train_num = len(data_files) - test_num\n",
    "        shuffled_index = np.random.permutation(len(data_files))\n",
    "\n",
    "        train_fname = [data_files[i] for i in shuffled_index[:train_num]]\n",
    "        test_fname = [data_files[i] for i in shuffled_index[-test_num:]]\n",
    "\n",
    "        label_file = pd.read_csv('../rsc/age_ixi_and_oasis.csv', index_col=0)\n",
    "\n",
    "        if test:\n",
    "            self.data_files = [data_files[i] for i in shuffled_index[-test_num:]]\n",
    "            self.label_file = label_file[task_type].values[shuffled_index[-test_num:]]\n",
    "\n",
    "        else:\n",
    "            self.data_files = [data_files[i] for i in shuffled_index[:train_num]]\n",
    "            self.label_file = label_file[task_type].values[shuffled_index[:train_num]]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.scaler == 'minmax':\n",
    "            x = np.load(self.data_files[idx])[55:201, 44:186, 20:193]\n",
    "            x = MinMaxScaler().fit_transform(x.reshape(-1, 1)).reshape(146, 142, 173)\n",
    "\n",
    "        else:\n",
    "            x = np.load(self.data_files[idx])\n",
    "            \n",
    "        x = torch.tensor(x)[None, :, :].float()\n",
    "        y = torch.tensor(self.label_file[idx]).float()\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:32.055636Z",
     "start_time": "2020-11-03T07:12:31.804706Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dset = MyDataset(task_type='age')\n",
    "test_dset = MyDataset(task_type='age', test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size=16)\n",
    "test_loader = DataLoader(test_dset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:32.086149Z",
     "start_time": "2020-11-03T07:12:32.063638Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class Levakov(nn.Module):\n",
    "\n",
    "    def __init__(self, task_type=None):\n",
    "        super(Levakov, self).__init__()\n",
    "        self.task_type = task_type\n",
    "\n",
    "        self.BN = nn.BatchNorm3d(1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 3), nn.ReLU(),\n",
    "            nn.Conv3d(8, 8, 3), nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(8)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(8,  16, 3), nn.ReLU(),\n",
    "            nn.Conv3d(16, 16, 3), nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.Dropout(.5)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, 3), nn.ReLU(),\n",
    "            nn.Conv3d(32, 32, 3), nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.Dropout(.5)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv3d(32, 64, 3), nn.ReLU(),\n",
    "            nn.Conv3d(64, 64, 3), nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.Dropout(.5)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.fc4 = nn.Linear(1024, 512)\n",
    "        self.fc5 = nn.Linear(512, 1)\n",
    "        self.dropout = nn.Dropout(.3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.BN(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:32.102144Z",
     "start_time": "2020-11-03T07:12:32.088141Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:34.392337Z",
     "start_time": "2020-11-03T07:12:32.103140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm3d-1        [-1, 1, 96, 96, 96]               2\n",
      "            Conv3d-2        [-1, 8, 94, 94, 94]             224\n",
      "              ReLU-3        [-1, 8, 94, 94, 94]               0\n",
      "            Conv3d-4        [-1, 8, 92, 92, 92]           1,736\n",
      "              ReLU-5        [-1, 8, 92, 92, 92]               0\n",
      "         MaxPool3d-6        [-1, 8, 46, 46, 46]               0\n",
      "       BatchNorm3d-7        [-1, 8, 46, 46, 46]              16\n",
      "            Conv3d-8       [-1, 16, 44, 44, 44]           3,472\n",
      "              ReLU-9       [-1, 16, 44, 44, 44]               0\n",
      "           Conv3d-10       [-1, 16, 42, 42, 42]           6,928\n",
      "             ReLU-11       [-1, 16, 42, 42, 42]               0\n",
      "        MaxPool3d-12       [-1, 16, 21, 21, 21]               0\n",
      "      BatchNorm3d-13       [-1, 16, 21, 21, 21]              32\n",
      "          Dropout-14       [-1, 16, 21, 21, 21]               0\n",
      "           Conv3d-15       [-1, 32, 19, 19, 19]          13,856\n",
      "             ReLU-16       [-1, 32, 19, 19, 19]               0\n",
      "           Conv3d-17       [-1, 32, 17, 17, 17]          27,680\n",
      "             ReLU-18       [-1, 32, 17, 17, 17]               0\n",
      "        MaxPool3d-19          [-1, 32, 8, 8, 8]               0\n",
      "      BatchNorm3d-20          [-1, 32, 8, 8, 8]              64\n",
      "          Dropout-21          [-1, 32, 8, 8, 8]               0\n",
      "           Conv3d-22          [-1, 64, 6, 6, 6]          55,360\n",
      "             ReLU-23          [-1, 64, 6, 6, 6]               0\n",
      "           Conv3d-24          [-1, 64, 4, 4, 4]         110,656\n",
      "             ReLU-25          [-1, 64, 4, 4, 4]               0\n",
      "        MaxPool3d-26          [-1, 64, 2, 2, 2]               0\n",
      "      BatchNorm3d-27          [-1, 64, 2, 2, 2]             128\n",
      "          Dropout-28          [-1, 64, 2, 2, 2]               0\n",
      "           Linear-29                  [-1, 256]         131,328\n",
      "          Dropout-30                  [-1, 256]               0\n",
      "           Linear-31                  [-1, 128]          32,896\n",
      "          Dropout-32                  [-1, 128]               0\n",
      "           Linear-33                    [-1, 1]             129\n",
      "================================================================\n",
      "Total params: 384,507\n",
      "Trainable params: 384,507\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.38\n",
      "Forward/backward pass size (MB): 263.77\n",
      "Params size (MB): 1.47\n",
      "Estimated Total Size (MB): 268.61\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Levakov().to(device)\n",
    "print(summary(model, input_size=(1, 96, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:34.408337Z",
     "start_time": "2020-11-03T07:12:34.394337Z"
    }
   },
   "outputs": [],
   "source": [
    "task_type = 'age'\n",
    "resize = True\n",
    "scheduler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:34.424394Z",
     "start_time": "2020-11-03T07:12:34.411338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T07:12:34.472340Z",
     "start_time": "2020-11-03T07:12:34.430344Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = SummaryWriter(f'./tensorboard/{datetime.now().strftime(\"%Y-%m-%d_%H%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T07:12:28.670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_losses, tst_losses = [], []\n",
    "best_loss = 0\n",
    "for e in range(300):\n",
    "\n",
    "    # TRAIN\n",
    "    trn_bth_loss = 0\n",
    "    trn_trues, trn_preds = [], []\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        if resize:\n",
    "            x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "        else:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model.forward(x).to(device)\n",
    "\n",
    "        trn_trues.append(y.to('cpu'))\n",
    "        trn_preds.append(y_pred.to('cpu'))\n",
    "\n",
    "        loss = torch.sqrt(loss_fn(y_pred.squeeze(1), y))\n",
    "        del x, y, y_pred\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler: scheduler.step()\n",
    "\n",
    "        trn_bth_loss += loss.item()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    ### loss\n",
    "    trn_losses.append(trn_bth_loss / len(train_loader))\n",
    "\n",
    "    ### collect trues/predictions\n",
    "    trn_trues = list(chain(*trn_trues))\n",
    "    trn_preds = list(chain(*trn_preds))\n",
    "\n",
    "        \n",
    "    # TEST\n",
    "    tst_bth_loss = 0\n",
    "    model.eval()\n",
    "    tst_trues, tst_preds = [], []\n",
    "    with torch.no_grad(): # to not give loads on GPU... :(\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            if resize:\n",
    "                x, y = F.interpolate(x, size=(96, 96, 96)).to(device), y.to(device)\n",
    "\n",
    "            else:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model.forward(x).to(device)\n",
    "\n",
    "            tst_trues.append(y.to('cpu'))\n",
    "            tst_preds.append(y_pred.to('cpu'))\n",
    "\n",
    "            loss = torch.sqrt(loss_fn(y_pred.squeeze(1), y))\n",
    "            del x, y, y_pred\n",
    "\n",
    "            tst_bth_loss += loss.item()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    ### loss\n",
    "    tst_losses.append(tst_bth_loss / len(test_loader))\n",
    "\n",
    "    ### collect trues/predictions\n",
    "    tst_trues = list(chain(*tst_trues))\n",
    "    tst_preds = list(chain(*tst_preds))\n",
    "    \n",
    "    reg_df = pd.DataFrame({\n",
    "        'True': list(map(float, trn_trues + tst_trues)),\n",
    "        'Prediction': list(map(float, trn_preds + tst_preds)),\n",
    "        'Label': ['train'] * 250 + ['test'] * 62\n",
    "    })\n",
    "\n",
    "    print(f'EPOCHS {e}')\n",
    "    print(f'TRAIN :: [LOSS] {trn_losses[-1]:.3f} | VALID :: [LOSS] {tst_losses[-1]:.3f}')\n",
    "    sns.lmplot(data=reg_df, x='True', y='Prediction', hue='Label')\n",
    "    plt.show()\n",
    "    \n",
    "    if best_loss - .02 > tst_losses[-1]:\n",
    "        \n",
    "        date = f'{datetime.now().strftime(\"%Y-%m-%d_%H%M\")}'\n",
    "        fname = f\"./models/{date}_{tst_losses[-1]:.3f}_model.pth\"\n",
    "        torch.save(model, fname)\n",
    "        best_loss = max(tst_losses[-1], best_loss)\n",
    "        \n",
    "    summary.add_scalars('loss/RMSE_loss',\n",
    "                         {'Train Loss': trn_losses[-1],\n",
    "                          'Valid Loss': tst_losses[-1]}, e)\n",
    "    \n",
    "    if e % 20 == 0:\n",
    "        plt.plot(trn_losses, label='Train')\n",
    "        plt.plot(tst_losses, label='Valid')\n",
    "        plt.title(f\"Losses among epochs, {e}th\")\n",
    "        #plt.ylim(0, 500)\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T07:12:28.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(trn_losses, label='Train')\n",
    "# plt.plot(tst_losses, label='Valid')\n",
    "# plt.title(\"Losses among epochs\")\n",
    "# plt.ylim(0, 500)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T07:12:28.673Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../2d_slice/src/slice_viewer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T07:12:28.674Z"
    }
   },
   "outputs": [],
   "source": [
    "# SliceViewer(np.array(train_dset[0][0][0])).triple_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
